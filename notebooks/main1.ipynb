{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM, Flatten, GlobalAveragePooling1D, LSTM, Reshape,Conv1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import itertools\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv('text_emotion.csv')\n",
    "train_data = pd.read_csv('emotion_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it makes me so fucking irate jesus. nobody is ...</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lol Adam the Bull with his fake outrage...</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@THATSSHAWTYLO passed away early this morning ...</td>\n",
       "      <td>0.354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Kristiann1125 lol wow i was gonna say really?...</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I need a \\xf0\\x9f\\x8d\\xb1sushi date\\xf0\\x9f\\x8...</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  sentiment_value\n",
       "0  it makes me so fucking irate jesus. nobody is ...            0.750\n",
       "1         Lol Adam the Bull with his fake outrage...            0.417\n",
       "2  @THATSSHAWTYLO passed away early this morning ...            0.354\n",
       "3  @Kristiann1125 lol wow i was gonna say really?...            0.438\n",
       "4  I need a \\xf0\\x9f\\x8d\\xb1sushi date\\xf0\\x9f\\x8...            0.271"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_class = len(np.unique(train_data.sentiment.values))\n",
    "y = train_data['sentiment_value'].values\n",
    "# num_class\n",
    "# np.unique(train_data.sentiment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 100\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data.content.values)\n",
    "post_seq = tokenizer.texts_to_sequences(train_data.content.values)\n",
    "post_seq_padded = pad_sequences(post_seq, maxlen=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,     1,  8443,   674],\n",
       "       [    0,     0,     0, ...,   657,   102, 12667],\n",
       "       [    0,     0,     0, ...,    40,    40,   809],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,    25,   554,   146],\n",
       "       [    0,     0,     0, ...,   271,   155,   701],\n",
       "       [    0,     0,     0, ...,   140,   321,   917]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "y = y.reshape(-1, 1)\n",
    "y = sc.fit_transform(y)\n",
    "# scalarX.fit(post_seq_padded)\n",
    "# scalarY.fit(y.reshape(1700,1))\n",
    "X_train, X_test, y_train, y_test = train_test_split(post_seq_padded, y, test_size=0.05)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_99 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 7,651\n",
      "Trainable params: 7,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5057 samples, validate on 1686 samples\n",
      "Epoch 1/10\n",
      "5057/5057 [==============================] - 2s 457us/step - loss: 105.6879 - mean_absolute_error: 5.5127 - val_loss: 15.0983 - val_mean_absolute_error: 2.6630\n",
      "Epoch 2/10\n",
      "5057/5057 [==============================] - 0s 26us/step - loss: 10.0073 - mean_absolute_error: 2.2313 - val_loss: 9.9811 - val_mean_absolute_error: 2.1830\n",
      "Epoch 3/10\n",
      "5057/5057 [==============================] - 0s 27us/step - loss: 5.7186 - mean_absolute_error: 1.7473 - val_loss: 7.2406 - val_mean_absolute_error: 1.9185\n",
      "Epoch 4/10\n",
      "5057/5057 [==============================] - 0s 26us/step - loss: 4.3098 - mean_absolute_error: 1.5476 - val_loss: 6.0671 - val_mean_absolute_error: 1.7440\n",
      "Epoch 5/10\n",
      "5057/5057 [==============================] - 0s 25us/step - loss: 3.6756 - mean_absolute_error: 1.4499 - val_loss: 4.9525 - val_mean_absolute_error: 1.5831\n",
      "Epoch 6/10\n",
      "5057/5057 [==============================] - 0s 24us/step - loss: 2.7934 - mean_absolute_error: 1.2934 - val_loss: 4.4328 - val_mean_absolute_error: 1.5163\n",
      "Epoch 7/10\n",
      "5057/5057 [==============================] - 0s 24us/step - loss: 2.2744 - mean_absolute_error: 1.1776 - val_loss: 3.9185 - val_mean_absolute_error: 1.4239\n",
      "Epoch 8/10\n",
      "5057/5057 [==============================] - 0s 25us/step - loss: 2.0639 - mean_absolute_error: 1.1346 - val_loss: 3.7580 - val_mean_absolute_error: 1.4002\n",
      "Epoch 9/10\n",
      "5057/5057 [==============================] - 0s 31us/step - loss: 1.9397 - mean_absolute_error: 1.1053 - val_loss: 3.5026 - val_mean_absolute_error: 1.3566\n",
      "Epoch 10/10\n",
      "5057/5057 [==============================] - 0s 28us/step - loss: 1.7796 - mean_absolute_error: 1.0600 - val_loss: 3.3116 - val_mean_absolute_error: 1.3271\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(MAX_LENGTH, ))\n",
    "embedding_layer = Embedding(vocab_size,\n",
    "                            128,\n",
    "                            input_length=MAX_LENGTH)(inputs)\n",
    "# # x = Dropout(0.1)(x)\n",
    "# x = Flatten()(embedding_layer)\n",
    "# # x = LSTM(64, input_shape=(32, 32), return_sequences=True)(embedding_layer)\n",
    "# # # x = Conv1D(128, 5, activation='relu')(embedding_layer)\n",
    "# # x = LSTM(64, input_shape=(32, 32), return_sequences=True)(x)\n",
    "# # # x = Dropout(0.1)(x)\n",
    "# # x = LSTM(32, input_shape=(32, 32))(x)\n",
    "# # # x = Dropout(0.1)(x)\n",
    "# x = Dense(64, input_dim=1,  kernel_initializer = 'uniform', activation='relu')(x)\n",
    "# x = Dense(32,  kernel_initializer = 'uniform', activation='relu')(x)\n",
    "# x = Dense(16,  kernel_initializer = 'uniform', activation='relu')(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=100, kernel_initializer = 'uniform', activation='relu'))\n",
    "model.add(Dense(50, kernel_initializer = 'uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='lecun_normal', activation='linear'))\n",
    "\n",
    "# predictions = Dense(1, kernel_initializer='lecun_normal', activation='linear')(x)\n",
    "# model = Model(inputs=[inputs], outputs=predictions)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])\n",
    "\n",
    "model.summary()\n",
    "filepath=\"weights-simple.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True)\n",
    "history = model.fit(X_train, batch_size=64, y=y_train, verbose=1, validation_split=0.25, \n",
    "          shuffle=True, epochs=10, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-35eecc9e635a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'validation_accuracy'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpointplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"epochs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_reg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpointplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"epochs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"validation_accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_reg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'green'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'epochs':history.epoch, 'accuracy': history.history['acc'], 'validation_accuracy': history.history['val_acc']})\n",
    "g = sns.pointplot(x=\"epochs\", y=\"accuracy\", data=df, fit_reg=False)\n",
    "g = sns.pointplot(x=\"epochs\", y=\"validation_accuracy\", data=df, fit_reg=False, color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)\n",
    "predicted = np.argmax(predicted, axis=1)\n",
    "# accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.62740567],\n",
       "       [ 0.11146153],\n",
       "       [-0.64181692],\n",
       "       [ 1.33940858],\n",
       "       [ 1.07627707],\n",
       "       [-0.5644253 ],\n",
       "       [-0.22390217],\n",
       "       [-1.647908  ],\n",
       "       [ 1.93790379],\n",
       "       [ 0.7563917 ],\n",
       "       [ 0.21980979],\n",
       "       [-0.09491613],\n",
       "       [ 0.11146153],\n",
       "       [-0.52314977],\n",
       "       [-0.75016519],\n",
       "       [-0.10523501],\n",
       "       [ 0.7563917 ],\n",
       "       [-1.44153034],\n",
       "       [ 0.32299862],\n",
       "       [ 0.7563917 ],\n",
       "       [ 0.00311326],\n",
       "       [ 0.86473997],\n",
       "       [-1.07005056],\n",
       "       [ 1.95854155],\n",
       "       [-1.17839883],\n",
       "       [-1.2867471 ],\n",
       "       [-1.39509537],\n",
       "       [-0.21358328],\n",
       "       [ 0.53969516],\n",
       "       [-0.64181692],\n",
       "       [-0.53346865],\n",
       "       [ 0.00311326],\n",
       "       [ 0.21980979],\n",
       "       [ 1.18462534],\n",
       "       [-1.50344364],\n",
       "       [ 1.40132188],\n",
       "       [ 1.72120725],\n",
       "       [ 1.29297361],\n",
       "       [-0.82239737],\n",
       "       [-0.10523501],\n",
       "       [ 2.27326748],\n",
       "       [ 1.69541004],\n",
       "       [ 0.53969516],\n",
       "       [ 0.32299862],\n",
       "       [ 1.40132188],\n",
       "       [ 1.61285898],\n",
       "       [ 0.00311326],\n",
       "       [-1.71498074],\n",
       "       [ 0.38491192],\n",
       "       [ 0.97308824],\n",
       "       [ 0.32299862],\n",
       "       [-1.17839883],\n",
       "       [-0.85851346],\n",
       "       [ 1.19494422],\n",
       "       [ 2.24231083],\n",
       "       [ 0.53969516],\n",
       "       [ 1.40132188],\n",
       "       [ 1.93790379],\n",
       "       [-0.31677211],\n",
       "       [-0.21358328],\n",
       "       [ 0.43134689],\n",
       "       [-0.82239737],\n",
       "       [-0.96686173],\n",
       "       [ 1.07627707],\n",
       "       [ 0.97308824],\n",
       "       [ 0.80798612],\n",
       "       [-1.34866039],\n",
       "       [ 1.07627707],\n",
       "       [-0.75016519],\n",
       "       [ 0.43134689],\n",
       "       [-0.85851346],\n",
       "       [-1.16807995],\n",
       "       [ 0.11146153],\n",
       "       [-1.60663247],\n",
       "       [ 1.24137919],\n",
       "       [ 0.21980979],\n",
       "       [-0.2651777 ],\n",
       "       [ 0.64804343],\n",
       "       [-0.22906161],\n",
       "       [ 0.26108533],\n",
       "       [ 0.29204197],\n",
       "       [ 0.65836232],\n",
       "       [-0.09491613],\n",
       "       [ 0.21980979],\n",
       "       [-0.64181692],\n",
       "       [-0.21358328],\n",
       "       [-0.21358328],\n",
       "       [-1.07005056],\n",
       "       [-0.4148015 ],\n",
       "       [ 0.97308824],\n",
       "       [-0.42512038],\n",
       "       [ 0.12178041],\n",
       "       [-0.9255862 ],\n",
       "       [ 0.6686812 ],\n",
       "       [-0.21358328],\n",
       "       [ 1.72120725],\n",
       "       [-0.31677211],\n",
       "       [-0.10523501],\n",
       "       [ 0.43134689],\n",
       "       [-1.93167727],\n",
       "       [ 0.10630208],\n",
       "       [ 0.5190574 ],\n",
       "       [ 0.00311326],\n",
       "       [ 2.04625206],\n",
       "       [ 0.49326019],\n",
       "       [-1.93167727],\n",
       "       [ 0.25076644],\n",
       "       [ 0.00311326],\n",
       "       [-1.71498074],\n",
       "       [-0.10007557],\n",
       "       [ 0.53969516],\n",
       "       [ 1.29297361],\n",
       "       [-1.17839883],\n",
       "       [ 0.64804343],\n",
       "       [ 2.15460032],\n",
       "       [-1.17839883],\n",
       "       [-0.37868541],\n",
       "       [-0.42512038],\n",
       "       [-1.02877503],\n",
       "       [-0.71920854],\n",
       "       [ 1.50967015],\n",
       "       [-0.31677211],\n",
       "       [ 1.40132188],\n",
       "       [ 0.7563917 ],\n",
       "       [ 0.11146153],\n",
       "       [ 0.53969516],\n",
       "       [ 0.50873851],\n",
       "       [-0.42512038],\n",
       "       [ 1.29297361],\n",
       "       [-0.22906161],\n",
       "       [-0.75016519],\n",
       "       [-0.10523501],\n",
       "       [-1.17839883],\n",
       "       [-1.17839883],\n",
       "       [-0.21358328],\n",
       "       [ 0.32299862],\n",
       "       [ 0.53969516],\n",
       "       [-0.85851346],\n",
       "       [ 0.21980979],\n",
       "       [ 1.50967015],\n",
       "       [ 0.11146153],\n",
       "       [ 0.53969516],\n",
       "       [ 0.00311326],\n",
       "       [-1.823329  ],\n",
       "       [ 1.82955552],\n",
       "       [ 0.00311326],\n",
       "       [-1.07005056],\n",
       "       [-1.07005056],\n",
       "       [ 1.65413451],\n",
       "       [-0.10523501],\n",
       "       [ 2.04625206],\n",
       "       [-0.9255862 ],\n",
       "       [ 0.86473997],\n",
       "       [ 0.21980979],\n",
       "       [ 2.15460032],\n",
       "       [-0.34256932],\n",
       "       [-0.64181692],\n",
       "       [ 1.40132188],\n",
       "       [ 0.21980979],\n",
       "       [-1.13196386],\n",
       "       [-0.96686173],\n",
       "       [ 0.21980979],\n",
       "       [-0.85851346],\n",
       "       [-1.13196386],\n",
       "       [ 0.21980979],\n",
       "       [ 0.93181271],\n",
       "       [-0.53346865],\n",
       "       [-1.35897928],\n",
       "       [ 0.20949091],\n",
       "       [ 0.10630208],\n",
       "       [ 0.43134689],\n",
       "       [-1.60663247],\n",
       "       [-0.21358328],\n",
       "       [ 0.21980979],\n",
       "       [ 0.5190574 ],\n",
       "       [ 0.7563917 ],\n",
       "       [-0.31677211],\n",
       "       [-0.96686173],\n",
       "       [-0.31677211],\n",
       "       [ 0.21980979],\n",
       "       [-0.85851346],\n",
       "       [ 1.29297361],\n",
       "       [ 0.11146153],\n",
       "       [ 1.42711909],\n",
       "       [ 0.7563917 ],\n",
       "       [ 1.13819037],\n",
       "       [ 0.62224623],\n",
       "       [-1.39509537],\n",
       "       [-0.53346865],\n",
       "       [ 0.30236086],\n",
       "       [ 0.32299862],\n",
       "       [ 0.72543505],\n",
       "       [-1.50344364],\n",
       "       [ 1.82955552],\n",
       "       [ 1.50967015],\n",
       "       [ 0.00311326],\n",
       "       [ 0.64804343],\n",
       "       [ 0.21980979],\n",
       "       [ 0.32299862],\n",
       "       [ 0.72543505],\n",
       "       [ 1.07627707],\n",
       "       [-1.41057369],\n",
       "       [ 2.04625206],\n",
       "       [ 0.64804343],\n",
       "       [-0.40964206],\n",
       "       [-1.17839883],\n",
       "       [-0.6521358 ],\n",
       "       [ 0.7563917 ],\n",
       "       [-1.07005056],\n",
       "       [-0.64181692],\n",
       "       [ 0.20433147],\n",
       "       [-1.823329  ],\n",
       "       [ 1.29297361],\n",
       "       [-1.17839883],\n",
       "       [ 0.43134689],\n",
       "       [-0.42512038],\n",
       "       [-0.76048407],\n",
       "       [ 1.13819037],\n",
       "       [ 0.53969516],\n",
       "       [-0.96686173],\n",
       "       [-0.31677211],\n",
       "       [-1.2867471 ],\n",
       "       [ 1.391003  ],\n",
       "       [ 1.29297361],\n",
       "       [-0.31677211],\n",
       "       [ 1.72120725],\n",
       "       [-0.42512038],\n",
       "       [ 0.64804343],\n",
       "       [-0.31677211],\n",
       "       [ 2.04625206],\n",
       "       [ 0.04954823],\n",
       "       [-0.15682943],\n",
       "       [-0.85851346],\n",
       "       [ 0.43134689],\n",
       "       [ 0.32299862],\n",
       "       [ 0.53969516],\n",
       "       [ 0.64804343],\n",
       "       [-1.95231504],\n",
       "       [-0.42512038],\n",
       "       [-0.31677211],\n",
       "       [-1.2867471 ],\n",
       "       [ 0.00311326],\n",
       "       [-1.33834151],\n",
       "       [-0.21358328],\n",
       "       [ 1.391003  ],\n",
       "       [-2.04002554],\n",
       "       [-1.07005056],\n",
       "       [ 0.7563917 ],\n",
       "       [-1.78205347],\n",
       "       [ 0.31267974],\n",
       "       [ 0.11146153],\n",
       "       [-1.93167727],\n",
       "       [ 2.26294859],\n",
       "       [ 0.32299862],\n",
       "       [-0.30645323],\n",
       "       [-0.21358328],\n",
       "       [ 0.81314556],\n",
       "       [ 1.75732334],\n",
       "       [ 0.32299862],\n",
       "       [-0.31677211],\n",
       "       [ 1.72120725],\n",
       "       [ 0.64804343],\n",
       "       [ 0.00311326],\n",
       "       [-0.42512038],\n",
       "       [-0.53346865],\n",
       "       [-0.31677211],\n",
       "       [-1.60663247],\n",
       "       [ 0.53969516],\n",
       "       [-0.75016519],\n",
       "       [ 1.06079875],\n",
       "       [-1.07005056],\n",
       "       [ 0.7563917 ],\n",
       "       [-1.50344364],\n",
       "       [ 1.40132188],\n",
       "       [ 0.84410221],\n",
       "       [ 1.29297361],\n",
       "       [-0.75016519],\n",
       "       [ 0.11146153],\n",
       "       [-0.75016519],\n",
       "       [-0.28065602],\n",
       "       [ 1.96370099],\n",
       "       [ 1.07627707],\n",
       "       [-0.10523501],\n",
       "       [ 0.86473997],\n",
       "       [ 1.07627707],\n",
       "       [ 0.43134689],\n",
       "       [-1.39509537],\n",
       "       [ 0.00311326],\n",
       "       [-0.64181692],\n",
       "       [-0.96686173],\n",
       "       [ 0.11146153],\n",
       "       [-0.10523501],\n",
       "       [-1.2867471 ],\n",
       "       [ 1.37552467],\n",
       "       [-0.10523501],\n",
       "       [ 1.82955552],\n",
       "       [-1.47248699],\n",
       "       [-0.31677211],\n",
       "       [-0.64181692],\n",
       "       [-1.50344364],\n",
       "       [-0.21358328],\n",
       "       [ 0.43134689],\n",
       "       [-0.10523501],\n",
       "       [-0.64181692],\n",
       "       [-1.17839883],\n",
       "       [-0.21358328],\n",
       "       [ 0.43134689],\n",
       "       [ 0.7563917 ],\n",
       "       [-0.64181692],\n",
       "       [ 0.62224623],\n",
       "       [ 2.15460032],\n",
       "       [-0.42512038],\n",
       "       [-0.42512038],\n",
       "       [-1.2867471 ],\n",
       "       [ 0.00311326],\n",
       "       [ 0.64804343],\n",
       "       [-0.53346865],\n",
       "       [ 0.7563917 ],\n",
       "       [-0.10523501],\n",
       "       [ 1.18462534],\n",
       "       [ 1.50967015],\n",
       "       [-0.96686173],\n",
       "       [-0.42512038],\n",
       "       [-0.42512038],\n",
       "       [-0.61601971],\n",
       "       [-0.96686173],\n",
       "       [-0.53346865],\n",
       "       [ 0.7563917 ],\n",
       "       [ 0.7563917 ],\n",
       "       [ 0.40554969],\n",
       "       [ 0.53969516],\n",
       "       [-1.07005056],\n",
       "       [ 0.97308824],\n",
       "       [-1.07005056],\n",
       "       [-0.10523501],\n",
       "       [ 0.43134689],\n",
       "       [-0.85851346],\n",
       "       [-0.64181692],\n",
       "       [-0.42512038],\n",
       "       [ 1.07627707],\n",
       "       [ 0.11146153],\n",
       "       [ 1.65413451],\n",
       "       [ 1.93790379],\n",
       "       [-0.30645323],\n",
       "       [-0.19810496],\n",
       "       [ 0.97308824],\n",
       "       [-0.96686173],\n",
       "       [ 0.19917203],\n",
       "       [-0.31677211],\n",
       "       [-1.20419604],\n",
       "       [ 1.96370099],\n",
       "       [-0.30645323],\n",
       "       [-0.44059871],\n",
       "       [-1.50344364],\n",
       "       [ 1.03500154]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-7c5afe3a3b44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcnf_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fayeed\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fayeed\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 81\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, predicted)\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnf_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-221aaebc2167>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'anger_disgust'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'joy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sadness'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shame_guilt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m plot_confusion_matrix(cnf_matrix, classes=class_names,\n\u001b[0m\u001b[0;32m      4\u001b[0m                       title='Confusion matrix, without normalization')\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cnf_matrix' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_names = ['anger_disgust', 'fear', 'joy','sadness', 'shame_guilt']\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnf_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-d154b2250eab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n\u001b[0m\u001b[0;32m      3\u001b[0m                       title='Normalized confusion matrix')\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cnf_matrix' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22, 0, 0, 0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = [\n",
    "  \"Watching the sopranos again from start to finish!\",\n",
    "  \"Finding out i have to go to the  dentist tomorrow\",\n",
    "  \"Sun in my eyes but I don't mind, what a beautiful day we've had in New York today!\",\n",
    "  \"Feels like someone's stabbed me in my hope\",\n",
    "  \"Do people have no Respect for themselves or you know others peoples homes\",\n",
    "  \"I want to go outside and chalk but I have no chalk\",\n",
    "  \"I hate coming to the doctors when I feel as if I might have a big problem\",\n",
    "  \"My mom wasn't mad\",\n",
    "  \"You don't indicate once I'm already in the road THEN rev and honk at me you stupid bitch #learnhowtodrive #bitch\",\n",
    "  \"Come home from work and this is on my doorstep. I guess he has a secret admirer\",\n",
    "  \"The 'egyption hot models' facebook page is pathetic... simply photos of obese horny women.\",\n",
    "  \"I HATE PAPERS AH #AH #HATE\",\n",
    "]\n",
    "\n",
    "post = \"\"\"West Bengal chief minister and Trinamool Congress (TMC) chief Mamata Banerjee's efforts to rename the state as 'Bangla' have again faced an obstacle from the Ministry of Home Affairs (MHA).\n",
    "\n",
    "According to The Indian Express, the home ministry has expressed concern over this move, saying that the name \"may sound like Bangladesh and that it would be difficult to differentiate the two at international forums\". The home ministry has written to the Ministry of External Affairs, the report said, to obtain an opinion before any further consideration.\n",
    "\n",
    "However, in 2016, Mamata had addressed the possibility of the name being confused with Bangladesh. Noting that the name 'Bangla' had historical significance, she had said, \"In English it will be Bengal, so that there will be no confusion with the name of neighbouring Bangladesh.\"\n",
    "\n",
    "File image of West Bengal chief minister Mamata Banerjee. PTIFile image of West Bengal chief minister Mamata Banerjee. PTI\n",
    "A constitutional amendment is required for a change in the name of a state. A recent example of the name of a state being changed was that of Odisha (earlier called Orissa).\n",
    "\n",
    "Banerjee's plans to rename the state have been taking shape since 2011, when the newly elected chief minister had put forward 'Paschim Banga' as an option.\n",
    "\n",
    "Banerjee's effort in 2011 never saw the light of day at the Centre, and was unsuccessful even in 2016 when the state Assembly passed a resolution to change the name of West Bengal to language-specific names. The cabinet had proposed that the name of the state be 'Bengal' in English, 'Bangla' in Bengali, and 'Bangal' in Hindi. Then, the home ministry had rejected the proposal saying that it would not be possible for a state to have different names in different languages.\n",
    "\n",
    "However, in July this year, the West Bengal Assembly unanimously passed a resolution to change the state's name to 'Bangla'.\n",
    "\n",
    "According to reports, the state's Assembly pushed more strongly for the renaming after the July 2016 Inter-State Council meeting in Delhi, when Banerjee was the last chief minister to address the Council because the speakers were listed in alphabetical order of the states. The name 'Bangla' would bump the state up in an alphabetically-organised list to number four.\n",
    "\n",
    "Apart from political repercussions of the move to rename the state, with the Left, Congress, and BJP state parties walking out of the Assembly in August 2016 over the issue, political analysts have warned against reigniting tensions in the Darjeeling and Kalimpong areas of the state. People residing in \"the hills\" as the areas are colloquially referred to, had in 2017 initiated a strong resistance to the state government's move to make Bengali a mandatory language in schools in the state.\n",
    "\n",
    "The Gorkha and Nepali communities of the state demanded a separate state \"Gorkhaland\" in protest and as an assertion of the linguistic differences in the state. Even though those protests were successfully pacified by the Mamata Banerjee-government after three months, experts believe that there continues to be a divide in socio-cultural aspects in the state.\n",
    "\n",
    "As this report by Marcus Dam points out, the attempt to rename the state may not go down well in the hills, as \"Bangla\" is also the locally accepted term for the Bengali language.\"\"\"\n",
    "\n",
    "list = post.split(\".\")\n",
    "\n",
    "post_seq = tokenizer.texts_to_sequences(list)\n",
    "post_seq_padded = pad_sequences(post_seq, maxlen=MAX_LENGTH)\n",
    "p = model.predict(post_seq_padded)\n",
    "p = np.argmax(p, axis=1)\n",
    "final = [0, 0, 0, 0]\n",
    "for i in p:\n",
    "    final[i] += 1\n",
    "\n",
    "final\n",
    "# for i, l in enumerate(list):\n",
    "#     print(l, \" : \", p[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7098, 2434)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 2434)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "def get_data(filename):\n",
    "    df = pandas.read_csv(filename)\n",
    "    df['content'] = df['content'].str.lower().replace('[^a-zA-Z0-9]', ' ', regex = True)\n",
    "    return df\n",
    "\n",
    "train_fn = 'emotion_classification.csv'\n",
    "# test_fn = 'salary-test-mini.csv'\n",
    "\n",
    "train = get_data(train_fn)\n",
    "# # test = get_data(test_fn)\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=5)\n",
    "# enc = DictVectorizer()\n",
    "# clf = Ridge(alpha=1.0, random_state=241,)\n",
    "# # train data set\n",
    "X_train = vectorizer.fit_transform(train['content'])\n",
    "print(X_train.shape)\n",
    "# X_train = hstack([X_train])\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_train, train['sentiment_value'], test_size=0.05)\n",
    "\n",
    "# # train the model\n",
    "# clf.fit(X_train, y_train)\n",
    "# rslt = clf.predict(X_test)\n",
    "# score = np.sqrt(mean_squared_error(rslt, y_test))\n",
    "# filename = 'intensity_anger.sav'\n",
    "# joblib.dump(clf, filename)\n",
    "# vect = joblib.dump(vectorizer, 'dump.sav')\n",
    "\n",
    "loaded_model = joblib.load(\"intensity_anger.sav\")\n",
    "vect = joblib.load('dump.sav')\n",
    "X_train = vect.transform([\"fuck off mother fucker dont fuck with me\"])\n",
    "X_train.shape\n",
    "# X_train = hstack([X_train])\n",
    "# print(X_train)\n",
    "# result = loaded_model.predict(X_train)\n",
    "# result\n",
    "# score = np.sqrt(mean_squared_error(rslt, y_test))\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Untitled0.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
