{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM, Flatten, GlobalAveragePooling1D, LSTM, Reshape,Conv1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import itertools\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv('text_emotion.csv')\n",
    "train_data = pd.read_csv('emotion_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it makes me so fucking irate jesus. nobody is ...</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lol Adam the Bull with his fake outrage...</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@THATSSHAWTYLO passed away early this morning ...</td>\n",
       "      <td>0.354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Kristiann1125 lol wow i was gonna say really?...</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I need a \\xf0\\x9f\\x8d\\xb1sushi date\\xf0\\x9f\\x8...</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  sentiment_value\n",
       "0  it makes me so fucking irate jesus. nobody is ...            0.750\n",
       "1         Lol Adam the Bull with his fake outrage...            0.417\n",
       "2  @THATSSHAWTYLO passed away early this morning ...            0.354\n",
       "3  @Kristiann1125 lol wow i was gonna say really?...            0.438\n",
       "4  I need a \\xf0\\x9f\\x8d\\xb1sushi date\\xf0\\x9f\\x8...            0.271"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75 ],\n",
       "       [0.417],\n",
       "       [0.354],\n",
       "       ...,\n",
       "       [0.417],\n",
       "       [0.889],\n",
       "       [0.828]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "y = train_data['sentiment_value'].values\n",
    "y = y.reshape(-1, 1)\n",
    "y = scaler.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 100\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data.content.values)\n",
    "post_seq = tokenizer.texts_to_sequences(train_data.content.values)\n",
    "post_seq_padded = pad_sequences(post_seq, maxlen=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,   310,    17,    14],\n",
       "       [    0,     0,     0, ...,     3,    27, 11410],\n",
       "       [    0,     0,     0, ...,     8,    15,   224],\n",
       "       ...,\n",
       "       [    0,     0,     0, ..., 12180,   244,    45],\n",
       "       [    0,     0,     0, ...,     1,  2218,  1340],\n",
       "       [    0,     0,     0, ...,   794,  1039, 15938]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(post_seq_padded, y, test_size=0.05)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 128)          2131072   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 64)           49408     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               16896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,374,145\n",
      "Trainable params: 2,374,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5057 samples, validate on 1686 samples\n",
      "Epoch 1/10\n",
      "5057/5057 [==============================] - 12s 2ms/step - loss: 0.1337 - mean_absolute_error: 0.2995 - val_loss: 0.0455 - val_mean_absolute_error: 0.1694\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04545, saving model to weights-simple.hdf5\n",
      "Epoch 2/10\n",
      "5057/5057 [==============================] - 10s 2ms/step - loss: 0.0392 - mean_absolute_error: 0.1610 - val_loss: 0.0379 - val_mean_absolute_error: 0.1577\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04545 to 0.03785, saving model to weights-simple.hdf5\n",
      "Epoch 3/10\n",
      "5057/5057 [==============================] - 10s 2ms/step - loss: 0.0345 - mean_absolute_error: 0.1521 - val_loss: 0.0347 - val_mean_absolute_error: 0.1519\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03785 to 0.03465, saving model to weights-simple.hdf5\n",
      "Epoch 4/10\n",
      "5057/5057 [==============================] - 9s 2ms/step - loss: 0.0252 - mean_absolute_error: 0.1260 - val_loss: 0.0301 - val_mean_absolute_error: 0.1372\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03465 to 0.03008, saving model to weights-simple.hdf5\n",
      "Epoch 5/10\n",
      "5057/5057 [==============================] - 9s 2ms/step - loss: 0.0166 - mean_absolute_error: 0.0992 - val_loss: 0.0293 - val_mean_absolute_error: 0.1360\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.03008 to 0.02935, saving model to weights-simple.hdf5\n",
      "Epoch 6/10\n",
      "5057/5057 [==============================] - 9s 2ms/step - loss: 0.0124 - mean_absolute_error: 0.0845 - val_loss: 0.0305 - val_mean_absolute_error: 0.1384\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.02935\n",
      "Epoch 7/10\n",
      "5057/5057 [==============================] - 9s 2ms/step - loss: 0.0096 - mean_absolute_error: 0.0726 - val_loss: 0.0315 - val_mean_absolute_error: 0.1402\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.02935\n",
      "Epoch 8/10\n",
      "5057/5057 [==============================] - 9s 2ms/step - loss: 0.0084 - mean_absolute_error: 0.0687 - val_loss: 0.0311 - val_mean_absolute_error: 0.1391\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02935\n",
      "Epoch 9/10\n",
      "5057/5057 [==============================] - 8s 2ms/step - loss: 0.0072 - mean_absolute_error: 0.0637 - val_loss: 0.0314 - val_mean_absolute_error: 0.1401\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02935\n",
      "Epoch 10/10\n",
      "5057/5057 [==============================] - 9s 2ms/step - loss: 0.0062 - mean_absolute_error: 0.0591 - val_loss: 0.0320 - val_mean_absolute_error: 0.1411\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02935\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(MAX_LENGTH, ))\n",
    "embedding_layer = Embedding(vocab_size,\n",
    "                            128,\n",
    "                            input_length=MAX_LENGTH)(inputs)\n",
    "# x = Flatten()(embedding_layer)\n",
    "x = LSTM(64, input_shape=(32, 32), return_sequences=True)(embedding_layer)\n",
    "# x = Conv1D(128, 5, activation='relu')(embedding_layer)\n",
    "# x = LSTM(64, input_shape=(32, 32), return_sequences=True)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = LSTM(32, input_shape=(32, 32))(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(512,  kernel_initializer = 'uniform', activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(256,  kernel_initializer = 'uniform', activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(128,  kernel_initializer = 'uniform', activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "predictions = Dense(1, kernel_initializer='lecun_normal', activation='linear')(x)\n",
    "model = Model(inputs=[inputs], outputs=predictions)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])\n",
    "\n",
    "model.summary()\n",
    "filepath=\"weights-simple.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "history = model.fit(X_train, batch_size=256, y=y_train, verbose=1, validation_split=0.25, \n",
    "          shuffle=True, epochs=10, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({'epochs':history.epoch, 'accuracy': history.history['val_acc'], 'validation_accuracy': history.history['val_acc']})\n",
    "# g = sns.pointplot(x=\"epochs\", y=\"accuracy\", data=df, fit_reg=False)\n",
    "# g = sns.pointplot(x=\"epochs\", y=\"validation_accuracy\", data=df, fit_reg=False, color='green')\n",
    "# from matplotlib import pyplot\n",
    "# pyplot.plot(history.history['mean_squared_error'])\n",
    "# pyplot.plot(history.history['mean_absolute_error'])\n",
    "# pyplot.plot(history.history['mean_absolute_percentage_error'])\n",
    "# pyplot.plot(history.history['cosine_proximity'])\n",
    "# pyplot.show()\n",
    "# history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8c6e9d315f93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# x = np.random.rand(355)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# len(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fayeed\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, data, **kwargs)\u001b[0m\n\u001b[0;32m   2791\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2792\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2793\u001b[1;33m         verts=verts, edgecolors=edgecolors, data=data, **kwargs)\n\u001b[0m\u001b[0;32m   2794\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2795\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fayeed\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1783\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1784\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1785\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1787\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32mc:\\users\\fayeed\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[0;32m   4154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4155\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_unit_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mydata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4156\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_xunits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4157\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_yunits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fayeed\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mconvert_xunits\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0max\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxaxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert_yunits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fayeed\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mconvert_units\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1519\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1520\u001b[0m         \u001b[1;31m# If x is already a number, doesn't need converting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1521\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mmunits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConversionInterface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_numlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1522\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fayeed\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\units.py\u001b[0m in \u001b[0;36mis_numlike\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \"\"\"\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mthisx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthisx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fayeed\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m       raise TypeError(\n\u001b[1;32m--> 457\u001b[1;33m           \u001b[1;34m\"Tensor objects are only iterable when eager execution is \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m           \"enabled. To iterate over this tensor use tf.map_fn.\")\n\u001b[0;32m    459\u001b[0m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted = model.predict(X_test)\n",
    "# predicted\n",
    "# predicted = np.argmax(predicted, axis=1)\n",
    "# accuracy_score(y_test, predicted)\n",
    "x = np.random.rand(355)\n",
    "len(x)\n",
    "plt.scatter(x[:20],predicted[:20])\n",
    "plt.scatter(x[:20],y_test[:20])\n",
    "from sklearn.metrics import mean_squared_error\n",
    "score = np.sqrt(mean_squared_error(predicted, y_test))\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaler.inverse_transform(y_test[1:20]), scaler.inverse_transform(predicted[1:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, predicted)\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['anger_disgust', 'fear', 'joy','sadness', 'shame_guilt']\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "  \"Watching the sopranos again from start to finish!\",\n",
    "  \"Finding out i have to go to the  dentist tomorrow\",\n",
    "  \"Sun in my eyes but I don't mind, what a beautiful day we've had in New York today!\",\n",
    "  \"Feels like someone's stabbed me in my hope\",\n",
    "  \"Do people have no Respect for themselves or you know others peoples homes\",\n",
    "  \"I want to go outside and chalk but I have no chalk\",\n",
    "  \"I hate coming to the doctors when I feel as if I might have a big problem\",\n",
    "  \"My mom wasn't mad\",\n",
    "  \"You don't indicate once I'm already in the road THEN rev and honk at me you stupid bitch #learnhowtodrive #bitch\",\n",
    "  \"Come home from work and this is on my doorstep. I guess he has a secret admirer\",\n",
    "  \"The 'egyption hot models' facebook page is pathetic... simply photos of obese horny women.\",\n",
    "  \"I HATE PAPERS AH #AH #HATE\",\n",
    "]\n",
    "\n",
    "post = \"\"\"West Bengal chief minister and Trinamool Congress (TMC) chief Mamata Banerjee's efforts to rename the state as 'Bangla' have again faced an obstacle from the Ministry of Home Affairs (MHA).\n",
    "\n",
    "According to The Indian Express, the home ministry has expressed concern over this move, saying that the name \"may sound like Bangladesh and that it would be difficult to differentiate the two at international forums\". The home ministry has written to the Ministry of External Affairs, the report said, to obtain an opinion before any further consideration.\n",
    "\n",
    "However, in 2016, Mamata had addressed the possibility of the name being confused with Bangladesh. Noting that the name 'Bangla' had historical significance, she had said, \"In English it will be Bengal, so that there will be no confusion with the name of neighbouring Bangladesh.\"\n",
    "\n",
    "File image of West Bengal chief minister Mamata Banerjee. PTIFile image of West Bengal chief minister Mamata Banerjee. PTI\n",
    "A constitutional amendment is required for a change in the name of a state. A recent example of the name of a state being changed was that of Odisha (earlier called Orissa).\n",
    "\n",
    "Banerjee's plans to rename the state have been taking shape since 2011, when the newly elected chief minister had put forward 'Paschim Banga' as an option.\n",
    "\n",
    "Banerjee's effort in 2011 never saw the light of day at the Centre, and was unsuccessful even in 2016 when the state Assembly passed a resolution to change the name of West Bengal to language-specific names. The cabinet had proposed that the name of the state be 'Bengal' in English, 'Bangla' in Bengali, and 'Bangal' in Hindi. Then, the home ministry had rejected the proposal saying that it would not be possible for a state to have different names in different languages.\n",
    "\n",
    "However, in July this year, the West Bengal Assembly unanimously passed a resolution to change the state's name to 'Bangla'.\n",
    "\n",
    "According to reports, the state's Assembly pushed more strongly for the renaming after the July 2016 Inter-State Council meeting in Delhi, when Banerjee was the last chief minister to address the Council because the speakers were listed in alphabetical order of the states. The name 'Bangla' would bump the state up in an alphabetically-organised list to number four.\n",
    "\n",
    "Apart from political repercussions of the move to rename the state, with the Left, Congress, and BJP state parties walking out of the Assembly in August 2016 over the issue, political analysts have warned against reigniting tensions in the Darjeeling and Kalimpong areas of the state. People residing in \"the hills\" as the areas are colloquially referred to, had in 2017 initiated a strong resistance to the state government's move to make Bengali a mandatory language in schools in the state.\n",
    "\n",
    "The Gorkha and Nepali communities of the state demanded a separate state \"Gorkhaland\" in protest and as an assertion of the linguistic differences in the state. Even though those protests were successfully pacified by the Mamata Banerjee-government after three months, experts believe that there continues to be a divide in socio-cultural aspects in the state.\n",
    "\n",
    "As this report by Marcus Dam points out, the attempt to rename the state may not go down well in the hills, as \"Bangla\" is also the locally accepted term for the Bengali language.\"\"\"\n",
    "\n",
    "list = post.split(\".\")\n",
    "\n",
    "post_seq = tokenizer.texts_to_sequences(list)\n",
    "post_seq_padded = pad_sequences(post_seq, maxlen=MAX_LENGTH)\n",
    "p = model.predict(post_seq_padded)\n",
    "p = np.argmax(p, axis=1)\n",
    "final = [0, 0, 0, 0]\n",
    "for i in p:\n",
    "    final[i] += 1\n",
    "\n",
    "final\n",
    "# for i, l in enumerate(list):\n",
    "#     print(l, \" : \", p[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "def get_data(filename):\n",
    "    df = pandas.read_csv(filename)\n",
    "    df['content'] = df['content'].str.lower().replace('[^a-zA-Z0-9]', ' ', regex = True)\n",
    "    return df\n",
    "\n",
    "train_fn = 'emotion_classification.csv'\n",
    "# test_fn = 'salary-test-mini.csv'\n",
    "\n",
    "train = get_data(train_fn)\n",
    "# # test = get_data(test_fn)\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=5)\n",
    "# enc = DictVectorizer()\n",
    "# clf = Ridge(alpha=1.0, random_state=241,)\n",
    "# # train data set\n",
    "X_train = vectorizer.fit_transform(train['content'])\n",
    "print(X_train.shape)\n",
    "# X_train = hstack([X_train])\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_train, train['sentiment_value'], test_size=0.05)\n",
    "\n",
    "# # train the model\n",
    "# clf.fit(X_train, y_train)\n",
    "# rslt = clf.predict(X_test)\n",
    "# score = np.sqrt(mean_squared_error(rslt, y_test))\n",
    "# filename = 'intensity_anger.sav'\n",
    "# joblib.dump(clf, filename)\n",
    "# vect = joblib.dump(vectorizer, 'dump.sav')\n",
    "\n",
    "loaded_model = joblib.load(\"intensity_anger.sav\")\n",
    "vect = joblib.load('dump.sav')\n",
    "X_train = vect.transform([\"fuck off mother fucker dont fuck with me\"])\n",
    "X_train.shape\n",
    "# X_train = hstack([X_train])\n",
    "# print(X_train)\n",
    "# result = loaded_model.predict(X_train)\n",
    "# result\n",
    "# score = np.sqrt(mean_squared_error(rslt, y_test))\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Untitled0.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
